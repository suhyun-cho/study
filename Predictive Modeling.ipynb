{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 예측 분석 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3장 데이터 전처리**\n",
    "#### 3.2 개별 예측 변수에 대한 데이터 변형\n",
    "* 중심화와 척도화\n",
    "    * 예측 변수를 중심화하는 방법은 예측 변수의 평균을 전체 값에서 빼는 것\n",
    "        * 중심화를 하고 나면 예측 변수의 평균이 0이 된다. \n",
    "    * 데이터를 척도화 하려면 예측 변수의 각 값을 표준편차로 나누면 된다.\n",
    "        * 척도화하면 해당 변수의 표준편차가 1이 된다.\n",
    "\n",
    "* 왜도 해결을 위한 변형\n",
    "    * 데이터에 로그 및 제곱근 값, 역을 취하면 왜도를 줄일 수 있다.\n",
    "    \n",
    "#### 3.3 여러 예측 변수 변형\n",
    "* 이상값 제거를 위한 데이터 변형\n",
    "    * 공간변형\n",
    "* 데이터 축소와 특징 추출\n",
    "    * PCA : 주성분이라고 알려진, 가장 가능한 분산에서 파악되는 예측 변수의 선형 조합을 찾는다.\n",
    "    * 첫번째 pc는 모든 가능한 선형 조합에서 가장 분산이 큰 예측 변수 측 변수의 선형 조합으로 정의된다.\n",
    "    * PCA의 장점이자 데이터 축소 방법이 모집단의 정보를 유지할 수 있는 이유는 연관되지 않은 성분들을 만들어 내기 때문이다.\n",
    "    * 예측 변수를 적절히 변환한 후 PCA를 적용하는 것이 좋다. \n",
    "      남길 예측 변수의 수를 결정하는 방법으로는, 각 성분에 번호를 붙인 후 이에 대한 요약되는 분산의 크기에 대해 스크리 그래프를 그리는 것.\n",
    "          * 스크리그래프 : 대부분의 데이터 세트에서 첫 번째 몇 개의 PC에서 분산의 대부분의 내용을 요약하므로 그래프는 급격히 기울것이다.\n",
    "          \n",
    "#### 3.4 결측값 처리\n",
    "* 정보성 결측값 (informative missingness) : 결측값의 패턴이 그 자체만으로도 하나의 정보가 되는 것.\n",
    "    * 정보성 결측값은 모델에 영향을 미치는 데이터 쏠림 현상을 유발한다\n",
    "* 중도 절단값 (censoring) : 원값이 누락됐지만, 다른 무언가를 통해 그 값을 추정할 수 있는 값.\n",
    "* 대치법 \n",
    "* case: 결측값에 영향을 받는 예측 변수가 몇개 되지 않는다면, 예측 변수 간의 관계에 대한 탐색적 분석 수행도 좋은 방법임.\n",
    "    * PCA같은 방법이나 시각화를 통해 예측 변수 간 강한 연관 관계가 있는지를 판단 할 수 있다. \n",
    "* K-최근접 이웃 모델 :\n",
    "    * 새 샘플에 대해 훈련 데이터 세트에서 가장 가까운 샘플들을 찾은 후, 그 샘플들의 평균을 내 값을 채우는 식으로 결측값을 대치한다 .\n",
    "        * 장점 : 대치된 데이터 값이 훈련 데이터 세트 값의 범위 안으로 한정된다는 것.\n",
    "        * 단점 : 전체 훈련 데이터 세트에서 매번 결측값을 대치해야 한다는 것.\n",
    "\n",
    "#### 3.5 예측 변수 제거\n",
    "* 우선, 데이터에서 고유한 값의 수가 샘플의 수에 비해 상대적으로 작은지 확인.\n",
    "* 가장 일반적으로 나타나는 값의 빈도 대비 두번째로 일반적인 값의 빈도 비는 (20정도로) 매우 크다.\n",
    "    * 예, 흥미로운 단어가 전체 531개 문서중에 523개에서 0개이고, 6개문서에서 2개일때 523/6 = 87 로 매우 크다.\n",
    "\n",
    "#### 3.6 예측 변수 간의 상관관계\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suhyun2",
   "language": "python",
   "name": "suhyun2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
