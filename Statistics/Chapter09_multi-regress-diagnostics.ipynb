{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고] https://godongyoung.github.io/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2018/01/20/ISL-linear-regression_ch3.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 다중선형회귀\n",
    "\n",
    "다중 선형 회귀분석은 설명번수 x가 2개이상, 반응변수 y가 1개인 선형 회귀분석이다. <br>\n",
    "### $Y_i = \\beta_0+\\beta_1 x_1i+ ... +\\beta_px_pi + \\epsilon_i$\n",
    "으로 표현되며 이에 수반되는 가정은 단순선형회귀모형과 마찬가지로 다음과 같다. <br>\n",
    "\n",
    "#### **[다중선형회귀에서의 가정]**\n",
    "* $\\beta_0, \\beta_1, ...,\\beta_p$ 는 절편과 각 설명변수에 해당하는 회귀모수이다.\n",
    "* 오차항은 $\\epsilon_i$들은 서로 독립이며 $N(0,\\sigma^2)$ 분포를 따른다.\n",
    "\n",
    "이 모형에서 미지의 모수는  $\\beta_0, \\beta_1, ...,\\beta_p$ 와 $\\sigma^2$ 이 되고, 이에대한 추정과 검정의 방법은 단순선형회귀모형에서와 매우 유사하다. <br>\n",
    "회귀계수  $\\beta_0, \\beta_1, ...,\\beta_p$ 는 편차제곱합인\n",
    "### $\\sum_{i=1}^n (Y_i - \\beta_0 -\\beta_1 x_1i - ...-\\beta_p x_pi)^2$\n",
    "을 최소화하는 최소제곱법으로 추정하고, 오차항의 분산인 $\\sigma^2$은 $\\beta$ 들에 대한 최소제곱추정량을 대입하여 <br>\n",
    "\n",
    "### $s^2 = \\frac{1}{n-p-1} \\sum_{i=1}^n (Y_i - \\beta_0 -\\beta_1 x_1i - ...-\\beta_p x_pi)^2$\n",
    "으로 추정한다 .<br>\n",
    "$s^2$ 은 잔차제곱합을 그 자유도인 n-p-1 로 나눈 거으로 단순선형회귀에서와 마찬가지로 분산분석표에서 나타나는 **평균제곱오차(MSE:Mean Square Error)**이다. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### **[다중선형회귀모형에서의 검정]**\n",
    "단순선형회귀모형에서는 회귀모형에 대한 F-검정이나 $H_0:\\beta_1 = 0$ 에 대한 t-검정이 동등했지만, <br>\n",
    "다중선형회귀모형에서는 회귀모형에 대한 F-검정과 $H_0:\\beta_1=\\beta_2=...=\\beta_p = 0$ 을 대립가설 $H_1:H_0$가 아님에 대해 검정하는 것으로, <br>\n",
    "회귀모형 전체가 유의미한지를 검정하는 것이고, <br>\n",
    "j=1,...,p 에 대한 $H_0:\\beta_j=0$ 의 t-검정은 j번째 설명변수와 반응변수의 선형관계가 유의한지 각 변수별로 검정하는 것이다. <br>\n",
    "\n",
    "[회귀모형 검정 -> t-검정] \n",
    "* $H_0:\\beta_1=\\beta_2=...=\\beta_p = 0$ <br>\n",
    "$\\beta_j$ 에 대한 신뢰수준이 $1-\\alpha$ 인 신뢰구간은 $\\frac{\\hat \\beta_j - \\beta_j}{\\hat{SE} (\\hat \\beta_j)}$ 가 자유도 n-p-1인 t분포를 따른다는 사실을 이용하여 아래와같이 구한다.\n",
    "### $\\hat \\beta_j \\pm t_\\frac{\\alpha}{2} (n-p-1) \\hat{SE} (\\hat \\beta_j)$\n",
    "\n",
    "[각 변수 별 검정 -> F-검정]\n",
    "* $H_0:\\beta_j=0$\n",
    "\n",
    "[각각의 자유도]   <br>\n",
    "* 전체제곱합의 자유도는 고나측값의 개수에서 1을 뺀 n-1\n",
    "* 회귀제곱합의 자유도는 설명변수의 개수인 p\n",
    "* 잔차제곱합의 자유도는 n-p-1 이다.\n",
    "\n",
    "* MSR = SSR/p\n",
    "* MSE = SSE/(n-p-1)\n",
    "* F = MSR/MSE\n",
    "\n",
    "F(p, n-p-1) 의 분포와 비교하여 분산비 F=MSR/MSE 의 관측값이 매우 크다면 , 이는 귀무가설에서 기대되는 것보다 평균회귀제곱이 상대적으로 크다는 뜻이므로 <br>\n",
    "F값이 클 때 귀무가설을 기각하고 반응변수와 설명변수 사이의 선형관계가 유의하다고 결론을 내린다\n",
    "<br>\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------------------\n",
    "### 다중회귀에서의 질문들 \n",
    "**1. p개의 독립변수 중 하나라도 유의한가? (==모든 회귀계수가 전부0은 아닌가?)**<br>\n",
    "하나의 변수에 대한 검정에서는 $F = t^2$ 이다.\n",
    "\n",
    "Q : 각 계수에 대한 t-test p-value를 보면 안되고, 전체에 대한 F검정을 해야하는 이유 ? <br>\n",
    "\n",
    "A1 : 변수p가 100개이고, 모두 유의미하지 않은 변수 ($\\beta_i =0$) 일지라도 5개 변수 정도가 확률적으로 유의한 p-value를 가질수도있음 .<br>\n",
    "그러나 F검정은 변수의 갯수도 고려를 하기에 전체에 대한 p-value를 구할 수 있음.\n",
    "(다른 글) <br>\n",
    "\n",
    "A2 : 실제로 모든 회귀계수가 0이라고 가정했을 때, <br>\n",
    "유의수준 5%로 개별 회귀계수에 대한 t-test를 한다면, 1종 오류로 인해서 100개 중 5개의 회귀계수는 유의한 값인 것으로 결론을 낼 것이다. 실제로 모두 유의하지 않은 경우라도<br>\n",
    "다중회귀분석에서는 이런 현상을 방지하기 위해서 우선 F-test를 하고, 전부 유의하지 않은 값은 아니라는 사실을 밝혀낸 뒤, <br>\n",
    "개별 회귀계수에 대한 t-test를 진행해 선형관계를 밝혀낸다.<br>\n",
    "\n",
    "=> 추가로, 만약에 R2랑 F값은 높은데, 개별 t 값은 유의하지 않을 경우 변수 간 상관관계가 높다고 의심할 수 있다. 이 경우 문제가 되는 변수들을 제거해야 한다.\n",
    "\n",
    "**2. 그럼 모든p가 유의한가, 그중 몇개만 유의한가?**<br>\n",
    "전체에 대한 F검정이 유의하다 나오면(즉 전부다 쓸모 없지는 않다.), 그중 어떤 변수를 써야할까? 이때 쓰이는게 변수선택법. <br>\n",
    "추가적으로 모델을 평가하기 위한 기준으론 AIC, BIC, Mallow’s CP등이 있다.\n",
    "* 전진 선택법 : \n",
    "    * 아무 변수도 포함되지 않은 모델에서 t통계량이 제일 유의한 변수 한개를 넣는다\n",
    "* 후진 제거법 : \n",
    "    * 모든 변수가 있는 모델에서 제일 큰 p-value를 가진 변수를 지움\n",
    "* 전진 단계적 회귀 (mixed selection)\n",
    "    * 아무 변수도 포함되지 않은 모델에서 t통계량이 제일 유의한 변수 한개를 넣는다 <br>\n",
    "    해당 변수를 넣은 상태에서 p-value를 계산해서 유의미 하지 않은 변수를 지운다 <br>\n",
    "    (이때 들어오기 위한 p-value임계점과 나가는 임계점을 다르게 한다. 보통 어렵게 들어오고(α=0.1) 쉽게 뺀다(α=0.15) )\n",
    "\n",
    "**3. 우리 데이터에 얼마나 잘 적합됬는가**<br>\n",
    "MSE와 $R^2$로 구한다. 근데 다중 회귀에선$R^2$이 cor(X,Y)를 구하는건 더이상 될 수 없고(변수가 1개가 아니니까) cor(Y^,Y)의 제곱과 같다. <br>\n",
    "least square는 주어진 자료 하에서 이 cor을 최대로 만드는 linear모델을 찾아준다. <br>\n",
    "\n",
    "그러나 $R^2$는 변수를 추가하면 할수록 항상 증가한다. 아주 쓸모없는 변수이더라도 least square에 따라 주어진 데이터에서 조금이라도 더 적합을 하게 된다. <br>\n",
    "이는 주어진 데이터에 지나치게 과적합(overfitting)을 하게 되는것으로, 이러한 성질때문에 모델을 비교할때는 $R^2$외에 변수의 숫자도 고려한 지표를 사용한다. <br> \n",
    "변수를 추가함으로써 생기는 위험이 (모델의 복잡도 혹은 overfit) 추가함으로써 생기는 설명력보다 큰지를 고려하는것이다. **AIC, BIC**등등 <br>\n",
    "\n",
    "**4. 우리의 예측은 얼마나 정확할 것인가?**<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "## 9.3 회귀진단\n",
    "### 9.3.1 잔차분석\n",
    "회귀분석의 최종결과를 받아들이기 전에 오차에 대한 등분산성, 독립성, 정규성 가정과 설명변수들의 선형성에 대한 검토가 필요하다. \n",
    "* 오차항인 $\\epsilon$은 관측되지 않으므로 , 대신 잔차의 분포를 통해 오차에 대한 가정을 확인하게 된다. \n",
    "    * $\\epsilon$ 대신 $\\hat \\epsilon$. \n",
    "    * 오차 $\\epsilon$을 추정된 모형을 이용하여 구한 결과가 잔차 $\\hat \\epsilon$이므로, 회귀모형의 기본가정들이 다 타당하다면 <br>\n",
    "    잔차 $\\hat \\epsilon_1, ...,\\hat \\epsilon_n$은 평균이 0이고 분산이 $\\sigma^2$에 가까운 정규분포를 따르고 <br>\n",
    "    $i \\ne j$ 일때 $\\hat \\epsilon_i$ 와 $\\hat \\epsilon_j$ 는 서로 관련성이 거의 없을것으로 기대.<br>\n",
    "\n",
    "<img src=\"residual.PNG\" width=\"700\"> <br>\n",
    "\n",
    "(왼쪽 위) <br>\n",
    "이상적인 형태의 잔차그림이다 .잔차들이 0을 중심으로 특정한 형태가 없이 랜덤하게 퍼져 있는데, <br>\n",
    "이는 오차항의 기댓값이 0이고 등분산성을 갖는다는 가정에 잘 부합되는 근거이다.\n",
    "\n",
    "(오른쪽 위) <br>\n",
    "가운데가 볼록한 형태를 보이고 있는데, 이는 Y의 조건부 기대값이 설명변수에 대해 선형이 아님을 암시한다고볼 수 있다. <br>\n",
    "관계가 곡선인 경우 비선형회귀를 이용하거나 변수변환을 생각해 볼 수 있다. <br>\n",
    "\n",
    "(왼쪽 아래) <br>\n",
    "한군데에 잔차들이 몰려있다. 이는 오차의 등분산성의 조건이 만족되지 않는다는 것을 암시한다. <br>\n",
    "이럴 때는 반응변수의 변환을 통해 분산을 동일하게 만들 수 있는지 확인할 필요가 있다.<br>\n",
    "\n",
    "(오른쪽 아래) <br>\n",
    "잔차가 순환하는 모양을 보여준다면, 이는 시간에 따른 흐름을 보여주는 데이터일 확률이 높다. <br>\n",
    "즉, 데이터가 독립적이지 못하다는 것을 의미한다.\n",
    "\n",
    "### 9.3.2 기타사항\n",
    "#### 1. 외삽(extrapolation)\n",
    "회귀직선을 적합하는 데에 사용한 설명변수의 값의 범위 밖에 있는 설명변수의 값에 대한 반응변수의 값을 예측하기 위해 회귀직선을 사용하는 것 .<br>\n",
    "\n",
    "    ex) 2~15세 남자아이들의 키의 중위수 산점도는 증가 추세를 보이는데, <br>\n",
    "    이때의 회귀식에 x값으로 30세 를 대입할 경우 261.55센티가 나오므로 이는 적합하지 않다. \n",
    "\n",
    "#### 2. 영향점 (influential point)\n",
    "회귀모형이 특정한 한두 개의 관측값에 과도하게 의존한다면, 표본에 따라 모형이 크게 변하게 되는 등 모형의 안정성에 문제가 생길 수 있다. <br>\n",
    "어떤 관측값이 자료에 포함되었을 때와 포함되지 않았을 때 회귀모형적합이 많이 달라지는 경우 ,<br>\n",
    "이 관측값을 영향점이라고 한다 . <br>\n",
    "=> 흔히 설명변수가 갖는 값이 다른 관측값들과 많이 다른 관측값이 영향점이 된다.\n",
    "\n",
    "#### 3. 변수변환  \n",
    "반응변수와 설명변수의 관계가 비선형이더라도, 때로 적절한 변수변환을 통해 선형관계로 바뀔 수 있는 경우가 있다. <br>\n",
    "가령, 반응변수와 설명변수 사이의 관계가 $E(Y|x) = ae^{bx}$ 로 곡선일 때 Y를 $log(Y)$로 변환하면, <br>\n",
    "$log(Y)=log(a) + bx$가 되어 선형회귀가 가능하게 된다.\n",
    "\n",
    "#### 4. 변수선택\n",
    "설명변수들이 서로 강하게 연관되어 있는 경우에는 회귀계수의 추정량이 분산이 커져서 추정결과가 불안정해질 수 있고, <br>\n",
    "분산분석에서의 F-검정을 통해 회귀모형이 유의하다고 판단되는 경우에도  모든 회귀계수의 t-검정결과가 유의하지 않은 경우도 생길 수 있다. <br>\n",
    "\n",
    "회귀계수의 t-검정은 다른 설명변수가 모두 모형에 들어가 있다는 가정하에 추가적인 효과를 검정하는 것이기 때문이다.<br>\n",
    "\n",
    "* 전진선택법 (forward selection)\n",
    "* 후진 제거법(backward elimination)\n",
    "* 단계적 회귀 (stepwise regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suhyun2",
   "language": "python",
   "name": "suhyun2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
