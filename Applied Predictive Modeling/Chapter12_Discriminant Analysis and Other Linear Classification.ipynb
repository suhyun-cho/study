{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 예측 분석 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **12장. 판별 분석 및 기타 선형 분류 모델**\n",
    "\n",
    "### 12.1 사례연구 : 성공적인 보조금 신청 예측\n",
    "Odds라는 것은 각 독립변수에 대해 실패/성공에 대한 확률을 구한 뒤, 각각 구하는 것이며 각 약에 대한 생존 Odds가 구해지면 Odds ratio도 계산할 수 있다. <br>\n",
    "* 오즈비 = 교차비 = 승산비 = 대응위험도 라는 표현도 쓴다.\n",
    "\n",
    "오즈 비 : 실패에 비해 성공할 확률의 비 <br>\n",
    "* ex) 게임에서 이길 확률이 1/5, 질 확률이 4/5이면, 게임에서 이길 odds 는 1/4 = ($\\frac{1/5}{4/5}$) 이 되며, <br>\n",
    "    계산된 값을 바탕으로 5번 중에 4번 질 동안 1번 이긴다 라고 해석한다.\n",
    "* 높은 오즈 비를 통해 이 예측 변수가 다른 분류 모델을 개발할 때도 영향력이 있을 것이라고 예상할 수 있다.\n",
    "\n",
    "모델을 튜닝하는 두가지 방식의 예 (서포트 벡터 머신에 대한 2개의 튜닝 인수 프로파일) <br>\n",
    "* 첫 번째 모델은 모든 2008년 이전 데이터와 25%의 2008년 데이터를 포함하는 8189개의 지원서를 사용해 만들었다.\n",
    "* 두 번째 모델은 2008년 이전 데이터를 사용해 구축한 후, 2008년 원서 데이터에 대한 ROC곡선 면적이 가장 큰 튜닝 인수값을 선택했다.\n",
    "\n",
    "=> 즉, 여기서는 2008년 이전 데이터와 2008년 데이터 일부(1557)를 훈련데이터로 사용하고, 2008년 데이터 518개를 최종 테스트 데이터로 사용한다.\n",
    "\n",
    "### 12.2 로지스틱 회귀\n",
    "이전 장을 되돌아 보면, <br>\n",
    "선형회귀는 변수들 간에 선형관계를 이루고, 잔차 제곱합을 최소화하는 식으로 변수를 선택하는 모델 형태이다. <br>\n",
    "잔차 제곱합을 최소화 하는 모델은 모델 **잔차가 정규분포**를 따른다고 가정할 수 있는 경우, 인수의 **우도 추정값**을 최대로 만든다는 것으로 알려져있다. <br>\n",
    "\n",
    "* 우도(likelihood)\n",
    "    * 확률 밀도 함수를 랜덤변수의 값 x의 함수가 아닌 파라미터 $\\theta$ 의 함수로 보는 것\n",
    "    * 확률 분포로부터 특정한 샘플 값 x가 발생했을 때, 이 샘플 값 x가 나오게 하는 파라미터 $\\theta$의 가능성\n",
    "    * 확률 분포로부터 특정한 샘플 값 x가 발생했을 때, 샘플 값 x와 변수 $\\theta$ 에서의 확률 (밀도함수)\n",
    "    \n",
    "* 최대 우도 추정 (Maximum Likelihood Estimation)\n",
    "    * 주어진 샘플 x에 대해 우도를 가장 크게 해주는 모수 $\\theta$ 를 찾는 방법. \n",
    "\n",
    "* 최대 우도 변수 추정은 데이터의 확률 분포에 대한 가정을 하고자 할 때 사용\n",
    "\n",
    "#### **로지스틱 회귀**\n",
    "반응변수(y)가 1/0인 상황에서 $y = \\beta_0 + \\beta X$ 이 식의 계수를 추정한다고 했을 때, <br>\n",
    "로지스틱 회귀분석에서는 보통 우리가 예측하고자 하는 y의 '예측값'이 P[Y=1] 이라는 믿음을 갖는데, 그러면 y의 예측값은 0-1사이로 고정이 되어야 한다. <br>\n",
    "하지만 위 식의 경우 특정 X값에서는 y의 예측값이 0-1사이로 고정되는 것이 아니라 0보다 작아질 수도 있고, 1보다 커질 수도 있다. <br>\n",
    "\n",
    "=> 즉, 좌변의 범위는 0-1이며 우변의 범위는 마이너스 무한대에서 플러스 무한대의 값을 갖게 된다. <br>\n",
    "    이를 해결하기 위해 로지스틱 회귀에서는 반응 변수에 대한 **로짓 변환**을 실시한다.(로짓변환은 y를 $log \\frac{y}{1-y}$ 로 만드는 함수적 변환을 말함.)\n",
    "\n",
    "* 다중선형 회귀분석 : $Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_P x_P$\n",
    "* 로지스틱 회귀분석 : $log(\\frac{p}{1-p}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_P x_P$\n",
    "=> 즉, 로지스틱 회귀분석은 일반회귀모형의 링크함수를 로짓으로 변형한 분석이다.\n",
    "\n",
    "* 로그 오즈의 범위는 -무한대에서 +무한대까지 될 수 있으므로, 선형 예측 변수의 값의 범위는 고려하지 않아도 된다.\n",
    "* 이 비선형 함수는 모델 항목에 대한 시그모이드 함수로, 확률 추정값을 0과 1사이로 제한한다.\n",
    "    * 또한 이 모델에서 사용되는 변수는 비선형 데이터 임에도 불구하고 모델에서는 선형 클래스 경계를 만든다.\n",
    "\n",
    "* 로지스틱 회귀 모델에서는, 일반적인 통계적 가설 검정을 통해 각 변수의 기울기가 통계적으로 유의한지를 구할 수 있다. (일반적으로 Z통계량 사용)\n",
    "\n",
    "### 12.5 벌점모델\n",
    "로지스틱 회귀모델에 벌점항을 추가하는 경우, 이는 릿지회귀와 매우 유사한 형태가 된다. <br>\n",
    "로지스틱 회귀 모델에서는 이항 우도 함수 L(p)의 값을 최대화하는 인수값을 찾는다. <br>\n",
    "아래를 최대로 하는 인수값을 찾는 것. <br>\n",
    "$log L(p) - \\lambda \\sum_{j=1}^P \\beta_j^2 $\n",
    "\n",
    "glmnet모델은 엘라스틱 넷과 마찬가지로 능형 회귀와 라소 벌점을 동시에 사용하지만, 벌점의 구조는 약간 다르다. <br>\n",
    "$logL(p) - \\lambda [(1-\\alpha)\\frac{1}{2} \\sum_{j=1}^P \\beta_j^2 + \\alpha \\sum_{j=1}^P |\\beta_j|]$ <br>\n",
    "여기서 $\\alpha$ 는 \"혼합 비율\"로 이 값에 따라 라소 벌점만 사용할 때 ($\\alpha$)와 릿지 회귀 벌점만을 사용할 때 ($\\alpha = 0$) 를 조절한다. <br>\n",
    "다른 튜닝인수 $\\lambda$는 전체 벌점 양을 조절한다.\n",
    "\n",
    "### 12.6 최근접 축소 중심 모델\n",
    "최근접 축소 중심 모델(predictive analysis for microarrays, PAM)이라고도 한다. <br>\n",
    "각 클래스에 대한 훈련 데이터의 각 예측 변수의 평균값을 구해 데이터의 중심값으로 사용한다. <br>\n",
    "예측 변수가 특정 클래스에 대해 충분한 정보를 갖고 있지 않은 경우, 이 클래스의 중심값은 전체 중심값에 가까울 것이다. <br>\n",
    "\n",
    "꽃받침 너비 예시의 경우, <br>\n",
    "virginica 중심이 전체 중심값에 도달하면, 꽃받침 너비는 versicolor 나 setosa인 꽃 분류에만 사용된다는 말이다. <br>\n",
    "예측 변수가 중심값에 도달하면, 이 변수는 더 이상 모델에서 사용하지 않게 된다. <br>\n",
    "결과적으로 최근접 축소 중심 모델은 모델 훈련 과정 중에 특징 선택까지 동시에 수행한다. <br>\n",
    "* 이 모델은 축소 튜닝 변수로 조절 가능한 특징 선택 기능이 내장돼 있어서 예측 변수가 많은 문제에 유용하다. \n",
    "    * 최근접 축소 중심 방법은 원래 예측 변수 수가 많고, 샘플 수는 적은 데이터에 적용하기 위해 만들어졌다.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suhyun2",
   "language": "python",
   "name": "suhyun2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
