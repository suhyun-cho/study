{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 예측 분석 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11장. 분류 모델에서의 성능 측정**\n",
    "범주형 응답 변수에 대한 모델 구축 및 평가\n",
    "* RMSE나 $R^2$ 같은 지표는 분류 목적으로는 적합하지 않음.\n",
    "\n",
    "### 11.1 클래스 분류\n",
    "* 분류 모델은 예측값을 보통 확률 형태의 연속값으로 만든다\n",
    "* 신경망이나 부분 최소 제곱같은 모델을 분류에 사용할 경우, 0과 1사이로 합이 1이 돼야 하는 규칙을 따르지 않는 연속값을 생성하므로 <br>\n",
    "이런 경우 예측값을 \"확률 같은\" 값으로 변환해 분류에서 해석 가능하도록 하는 '소프트맥스' softmax 변환 방법이 있다.\n",
    "\n",
    "[잘 보정된 확률]\n",
    "* 클래스별 확률의 품질을 평가할 때 사용하는 것 중 한가지 방법은 *보정그래프* 를 사용하는 것이다.\n",
    "    * 사건별 관측 확률 대비 예측 클래스 확률을 보여준다.\n",
    "* 보정 그래프에서는 x축에 집합의 중간값을 나타내고, y축에는 관측 사건 확률을 표시한다.\n",
    "\n",
    "[클래스 확률 나타내기] \n",
    "* 3개 이상의 클래스가 있는 경우, 클래스 확률의 히트맵을 사용해 예측 신뢰도를 측정할 수 있다.\n",
    "\n",
    "[중간 지대]\n",
    "* 분류 성능을 높이기 위한 방법으로 신뢰도가 낮아 클래스가 명확히 구분되지 않는 *애매한 지점* 또는 *중간 지대*를 만드는 방법이 있다.\n",
    "* 이런 경우, 모델 성능은 중간 지대의 샘플을 제외하고 계산한다. \n",
    "    * 이 때 성능 측정 시 \"애매한\" 것으로 분류되는 비율을 함께 명시해 미예측 분류율을 파악한다.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "### 11.2 분류 예측 평가\n",
    "**혼동행렬(confusion matrix)**\n",
    "혼동행렬은 데이터의 클래스 관측값과 예측값에 대한 단순한 표다. <br>\n",
    "\n",
    "#### 정확도(Accuracy) 의 단점\n",
    "* 총정확도는 만들어지는 오차의 **종류**에 대한 구분이 없다.\n",
    "    * 예를들어, 중요메일을 스팸으로 잘못 분류해서 이메일을 삭제하게 되는 비용은 스팸인 메일을 중요메일로 잘못 분류한 비용보다 크다. \n",
    "* 각 클래스의 자연적인 발생빈도를 고려해야 할 수도 있다.\n",
    "    * 예를들어, 800명 중 1명 또는 0.1%가 다운증후군이라고 했을 때 이 예측 모델이 모든 샘플이 다운증후군이 아니다 라고 예측하면 예측률은 거의 완벽할 것임. <br>\n",
    "    \n",
    "#### 무정보율(no-information rate)\n",
    "No Information Rate는 가장 많은 값이 발견된 분류의 비율이다. \n",
    "* 예를들어, 0이 4개, 1이 8개 있는 데이터의 경우 분류 1의 비율이 분류 0의 비율보다 높으므로 항상 1을 출력하면 정확도는 8/(4+8)=0.6667 이다. \n",
    "    * 실제 분류 알고리즘은 feature를 들여다보고 예측을 수행하므로 분류의 비율만 보고 결과를 출력했을 때의 정확도인 0.6667보다는 좋아야 한다.\n",
    "\n",
    "#### 카파 통계량 (Kappa statistic)\n",
    "=> 카파는 여러 평가자가 동일한 표본을 평가할 때 명목형 또는 순서형 평가의 합치도를 측정한다. <br>\n",
    "카파는 우연의 일치로 만들어진 정확성을 고려한 수치다. <br>\n",
    "\n",
    "$Kappa = \\frac{O-E}{1-E}$ <br>\n",
    "=> 여기서 O는 Observed accuracy로 실제 정확도, E는 Expected accuracy로 예측된 정확도를 의미. <br>\n",
    "* 이 통계량은 -1에서 1사이의 값을 갖는다.\n",
    "* 0인 경우 관측값과 예측값 간에 일치되는 값이 하나도 없다는 뜻이고, 1은 예측값과 관측값이 완벽하게 들어맞는다는 뜻이다.\n",
    "* 음의 값은 이 예측이 실제와는 반대라는 것을 나타낸다.\n",
    "    * 큰 음의 값을 갖는 카파는 어쨌든 예측 변수와 응답변수 간에 관계가 존재한다는 것을 나타내므로 예측 모델이 제대로 된 방향으로 관계를 찾고 있음을 의미한다.\n",
    "* 카파 값이 0.3 에서 0.5사이인 경우, 어느정도 일치한다고 볼 수 있다.\n",
    "* 카파 통계량은 2종 이상의 분류문제(low, medium, high) 에 대해 일치 정도를 평가하는데도 사용할 수 있다.\n",
    "    * Kappa에 가중치를 매겨 원래 값이 low인 샘플을 high라고 예측했을 때를, low샘플을 medium이라고 예측했을 때 보다 카파통계량을 더 떨어뜨릴 수 있다.\n",
    "\n",
    "**이종 문제**\n",
    "P = TP+FN <br>\n",
    "N = FP+TN <br>\n",
    "\n",
    "* True Positive (TP)\n",
    "* True Negative (TN)\n",
    "* False Negative (FN)\n",
    "* False Positive (FP) <br>\n",
    "\n",
    "=> 여기서 True는 실제값이 1이냐 0이냐를 맞췄다는 것을 나타내고, False는 틀렸다는 것을 나타냄.<br>\n",
    "=> Positive/Negative는 예측한 값이 1이냐 0이냐를 의미\n",
    "\n",
    "[정확도 (Accuracy)] <br>\n",
    "ACC = (TP+TN) / (전체 데이터 수 = P+N)<br>\n",
    "\n",
    "[민감도 (Sensitivity)]\n",
    "* 원래 Positive 데이터 수에서 Positive로 분류된 수. (ex. 암 양성이 100개있는데, 모델에 있어서 90개가 분류되었으면 Sensitive Rate=0.9)\n",
    "SN = TP / P\n",
    "\n",
    "[특이도 (Specify)]\n",
    "* Negative 로 판단한 것 중에, 실제 Negative 값의 비율\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### 11.3 클래스 확률 평가\n",
    "#### 시스팀 동작 특성(ROC)곡선\n",
    "* x축을 False Positive Rate(1-특이도) , y축을 True Positive Rate(민감도) 로 놓은 그래프\n",
    "    * 민감도 : 1인 케이스에 대해 1이라고 예측한 것.\n",
    "    * 특이도 : 0인 케이스에 대해 0이라고 예측한 것.\n",
    "    \n",
    "* ROC곡선은 X,Y가 둘다 [0,1]의 범위이고, (0,0)에서 (1,1)을 잇는 곡선임.\n",
    "    * 이때 ROC커브의 면적이 1에 가까울수록 (왼쪽 위 꼭지점에 다가갈수록) 좋은 성능이다.\n",
    "    * 그리고 면적 즉, AUC는 0.5~1의 범위를 갖는다.(0.5면 성능이 전혀 없음. 1이면 최고의 성능)\n",
    "    (AUC = the Area Under a ROC Curve, 커브의 밑 면적을 구한 값)\n",
    "\n",
    "* 장점 : 모델을 민감도와 특이도에 대한 함수로 정의함으로써 곡선이 클래스 비율에 영향을 받지 않는다는 것이다.\n",
    "* 단점 : 정보를 찾을 수 없다는 것이다.\n",
    "        (ex. 한 모델이 매우 가파른 ROC곡선을 그리지만, 다른 모델에 비해 AUC는 낮을 경우)\n",
    "\n",
    "* ROC곡선은 이종 문제에 대해서만 정의돼 있지만, 3개 이상의 클래스를 다루도록 확장할 수도 있다.\n",
    "\n",
    "(+)참고 <br>\n",
    "데이터 라벨의 분포가 심하게 불균등 할 때는 **PR그래프(Precision Recall Plot)**을 사용한다. <br>\n",
    "ex) 이상 거래 검출 시나리오의 경우 정상 거래의 비율이 비정상 거래에 비해서 압도적으로 많기 때문에 이런 경우는 ROC그래프보다 PR그래프가 분석에 더 유리하다.\n",
    "* PR그래프는 위쪽으로 갈수록 정확도가 높은 모델\n",
    "* PR그래프의 AUC값을 이용하여 모델의 정확도를 평가하는데, 이 경우는 Base Line = P/(P+N) 을 사용해서 베이스라인을 넘을 경우 쓸만한 모델이라고 봄. \n",
    "\n",
    "#### 리프트 도표 (lift curve, lift chart, gain curve, gain chart)\n",
    "* 소속집단의 실제확률보다는 레코드들간에 순위를 매기는 것에 관심을 둔다. \n",
    "* 상대적으로 사례를 적게 선택하고 상대적으로 높은 응답자 비율을 찾음으로써 가장 좋은 성과를 보이는 부분을 찾고자 할 때 유용.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suhyun2",
   "language": "python",
   "name": "suhyun2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
