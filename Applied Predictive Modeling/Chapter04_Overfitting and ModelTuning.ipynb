{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 예측 분석 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4장 과적합과 모델튜닝**\n",
    "* 모델 튜닝 : 갖고 있는 데이터를 사용해 모델의 실제 예측성능을 극대화할 수 있는 모델 변수를 설정해야 한다.\n",
    "    \n",
    "### 4.1 과적합 문제\n",
    "* 데이터의 일반적인 패턴을 학습한 경우, 모델은 각 샘플 특유의 잡음 성격에 대해서도 학습한다. \n",
    "이런 모델 유형을 '과적합됐다' 라고 한다.\n",
    "\n",
    "### 4.2 모델 튜닝\n",
    "* 최적의 인수를 찾는 방법 : 대부분의 모델에 적용 가능한 일반적인 접근 방식으로 가능한 값 후보군을 정한 후, \n",
    "후보군별로 모델 활용성에 대한 신뢰도를 계산하고 최적의 값을 선택하는 것.\n",
    "\n",
    "### 4.3 데이터 분할\n",
    "[모델 구축 단계]\n",
    "* 예측 데이터 전처리\n",
    "* 모델 변수 추정\n",
    "* 모델에 사용할 예측 변수 선정\n",
    "* 모델 성능 평가\n",
    "* 예측 규칙 미세 조정(ROC 곡선 등)\n",
    "\n",
    "[샘플링 방법]\n",
    "* 단순 임의 샘플링 \n",
    "    * 데이터에서 각 클래스의 비중 등 어떤 데이터의 속성도 고려하지 않는다.\n",
    "* 층위 임의 샘플링\n",
    "    * 세부 그룹에서 임의 샘플링하는 방식. 이 방식을 사용하면 두 데이터 세트의 결과분포의 우도가 보다 유사하게 나타남.\n",
    "* 최대 비유사도 샘플링\n",
    "    * 두 샘플의 예측 변수 간 거리를 구하는 것.\n",
    "    * 초기 샘플과 어느 세트에도 할당되지 않은 샘플 간의 비유사도를 구한다. 그 후 계산된 샘플 중 가장 유사하지 않은 샘플을 테스트 세트에 추가한다.\n",
    "\n",
    "### 4.4 리샘플링 기법\n",
    "* k-겹 교차 검증\n",
    "    * 임의로 크기가 대충 비슷한 k개의 집합으로 나눈다(보통5 또는 10을 사용). \n",
    "    5-겹 교차 검증일 경우, 첫 번째 모델은 첫 번째 폴드를 테스트로 사용하고 나머지 2~5까지를 훈련 세트로 사용하여 학습한다. <br>\n",
    "    두 번째 모델은 두 번째 폴드를 테스트로 사용하고 나머지 1,3~5까지를 훈련 세트로 사용하여 학습한다.<br>\n",
    "    k회 반복된 성능 측정값을 합산해(보통 평균과 오차를 사용한다) 튜닝 변수와 모델 계수 간의 관계를 파악한다.<br>\n",
    "        * k가 클수록 연산이 많아져서 부담스러울 수 있지만, 편향도는 줄어든다. k가 2나 3처럼 작은 경우, 편향도는 크지만 계산 효율성은 매우 좋다.<br>\n",
    "        (편향도 : 추정된 값과 실제 성능값의 차이)\n",
    "        \n",
    "* 단일 잔류 교차 검증 (Leave-one-out cross-validation LOOCV)\n",
    "    * 매번 1개의 샘플을 추출하고, 최종 성능은 k개의 개별 샘플에 대한 예측 결과로부터 구한다. \n",
    "\n",
    "* 반복적 훈련/테스트 세트 분할 (집합 잔류 교차 검증, 몬테 카를로 교차 검증으로 알려져 있다.)\n",
    "    * k-겹 교차검증 간의 차이점은 샘플이 추출된 부분 집합에 여러 번 나타날 수 있다는 것이다. 또한 보통 반복 횟수가 k-겹 교차 검증보다 크다. \n",
    "    * 반복 횟수가 중요한데, 사용자가 결과값이 좀 불안정해도 괜찮다면 25회 반복도 충분하다. 하지만 안정적인 성능 추정값을 얻고 싶다면 50~200회 가량을 추천한다.\n",
    "    \n",
    "* 부트스트랩\n",
    "    * 원본 데이터셋에서 중복을 허용하여 샘플링을 반복함으로써 모집단으로부터 새로운 데이터를 생성하는 방법. \n",
    "    보통, 부트스트랩 오차율은 k-겹 교차 검증에 비해 불확실성이 작게 나타난다. 하지만 평균적으로 부트스트랩 샘플 중 63.2%의 데이터가 한 번 이상 나타나므로 \n",
    "    이 기법을 사용하면 k ~ 2 인 경우의 k-겹 교차 검증과 비슷한 편향도를 보인다.\n",
    "\n",
    "### 4.7 추천하는 데이터 분할 방식\n",
    "* 리샘플링을 사용하지 않는 경우가 기본적으로는 더 낫다.\n",
    "* 샘플 크기가 작다면, 반복 10-겹 교차 검증 추천\n",
    "* 모델 중 나은 것을 고르거나 성능이 좋은 것을 찾으려면, 분산이 매우 낮은 부트스트랩 방식 중 하나 선택\n",
    "\n",
    "### 4.8 모델 선택\n",
    "[최종 모델의 유형을 결정하는 법]\n",
    "1. 가장 해석하기 어렵고 가장 유연한, 부스트 트리나 서포트 벡터 머신 같은 모델로부터 시작한다.\n",
    "2. 조금이라도 투명한 MARS, 부분 최소 자승법, 일반화 가법 모델, 나이브 베이지안 모델 같은 보다 단순한 모델을 탐색한다.\n",
    "3. 더 복잡한 방법의 성능에 어느 정도 근접하면서 가장 단순한 모델을 찾는다.\n",
    "\n",
    "* 비선형 서포트 벡터 머신이나 랜덤 포레스트 모델은 정확도가 높지만, 복잡도나 예측 방정식의 범위상 예측 방정식을 실제 시스템에 올리기에는 까다로울 수 있다. <br>\n",
    "하지만 MARS같이 보다 해석력이 높은 모델은 유사한 정확도를 갖고, 예측 방정식 구현이 쉬우며 실행 시간 측면에서도 훌륭하다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suhyun2",
   "language": "python",
   "name": "suhyun2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
