{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache-Hadoop\n",
    "T-academy 온라인강의 <br>\n",
    "https://tacademy.skplanet.com/live/player/onlineLectureDetail.action?seq=188\n",
    "\n",
    "## [4강] 하둡 분산파일시스템 이해(2)\n",
    "수강일 : 2020-11-26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "### 4-1) 하둡 명령어 실습\n",
    "\n",
    "* 홈 디렉토리에 하둡경로 설정해줌 <br>\n",
    "(base) josuhyeon-ui-MacBook-Pro:~ suhyun$ vi ~/.bash_profile\n",
    "\n",
    "export HADOOP_HOME=/Users/suhyun/Platform/hadoop-3.3.0 export <br> PATH=$HADOOP_HOME/bin:$PATH<br>\n",
    "\n",
    "* root경로\n",
    "    * hadoop fs -ls\n",
    "    * 하둡 네임노드한테 이 명령어를 던진것.\n",
    "    \n",
    "* (참고) local host도 연결을 해줘야 실행됨\n",
    "    * ssh localhost\n",
    "* (참고) ll 명령어 안먹어서 ls -l 명령어 입력하면 리스트 볼 수 있음.\n",
    "\n",
    "* DFS데몬 실행을 해야 connect됨.\n",
    "> * /Users/suhyun/Platform/hadoop-3.3.0 이 경로에서\n",
    "    * 먼저 포맷을 해주고 =>  bin/hdfs namenode -format \n",
    "    * dfs 데몬을 실행시켜야 connect됨. => sbin/start-dfs.sh \n",
    "* hadoop 경로\n",
    "    * /Users/suhyun/Platform/hadoop-3.3.0/etc/hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "* hadoop아래 파일확인\n",
    "    * hadoop fs -ls / <br>\n",
    "<br>\n",
    "* 아무것도 없을 경우, 먼저 user파일을 만들어야됨.\n",
    "    * hadoop fs -mkdir /user\n",
    "        * drwxr-xr-x   - suhyun supergroup          0 2020-11-26 08:59 /user<br>\n",
    "        <br>\n",
    "* 그다음에 새로만든 user에 들어가서\n",
    "    * hadoop fs -ls /user  (이때 -ls 뒤에 띄어쓰기해야됨)\n",
    "    * (base) josuhyeon-ui-MacBook-Pro:hadoop-3.3.0 suhyun$ hadoop fs -ls /user<br>\n",
    "    <br>\n",
    "    \n",
    "* 그안에서 새로 디렉토리를 만듬 (hadoop fs -mkdir /user/Hadoop)\n",
    "    * hadoop fs -mkdir /user/Hadoop\n",
    "    * (base) josuhyeon-ui-MacBook-Pro:hadoop-3.3.0 suhyun$ hadoop fs -mkdir /user/Hadoop<br>\n",
    "    <br>\n",
    "    * 디렉토리 하나 더만듬 => hadoop fs -mkdir /user/suhyun\n",
    "        * drwxr-xr-x   - suhyun supergroup          0 2020-11-26 08:59 /user/Hadoop\n",
    "        * drwxr-xr-x   - suhyun supergroup          0 2020-11-26 09:07 /user/suhyun<br>\n",
    "        <br>\n",
    "    * suhyun디렉토리안에 test용 하나더만듬 =>hadoop fs -mkdir /user/suhyun/hadoop_mkdir_test\n",
    "         * drwxr-xr-x   - suhyun supergroup          0 2020-11-26 09:09 /user/suhyun/hadoop_mkdir_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "#### 디렉토리에 파일을 복사하는법\n",
    "* hadoop fs -put LICENSE.txt hadoop_mkdir_test\n",
    "    * LICENSE.txt는 로컬 pc에 맥북에있는 파일이고, hadoop_mkdir_test는 원격에 있어야 하는 파일임. 네임노드에 넣겠다고 요청한것.\n",
    "    * 그럼 네임노드에 이 파일 이름은 뭐고, 크기는 얼마나되는지를 보내는것.\n",
    "    * 네임노드가 파일 이름과 크기를 보고, 맥북 에 떠 있는 클라이언트에 보냄.<br>\n",
    "<br>\n",
    "\n",
    "* 파일크기확인\n",
    "    * hadoop fs -ls -h hadoop_mkdir_test\n",
    "    *  결과 \n",
    "        * -rw-r--r--   1 suhyun supergroup     15.3 K 2020-11-26 09:11 hadoop_mkdir_test/LICENSE.txt\n",
    "  \n",
    "* 파일 읽기 (text 명령어)\n",
    "    * hadoop fs -text hadoop_mkdir_test/LICENSE.txt\n",
    "    * 로컬로 가져오지않고도 하둡에 있는 파일 내용을 볼 수 있음.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "### 4-2) 하둡 분산파일시스템(HDFS) 이론설명\n",
    "\n",
    "**Rack Awareness**\n",
    "* 랙 단위로 장애가 나는 경우가 있을 수 있음.\n",
    "\n",
    "**HDFS세이프 모드**\n",
    "* 세이프모드는 데이터 노드를 수정할 수 없는 상태\n",
    "* 세이프모드가 되면 데이터는 읽기 전용 상태가 되고, 데이터 추가와 수정이 불가능하며 데이터 복제도 일어나지 않음.\n",
    "\n",
    "**HDFS 휴지통 설명 및 명령어**\n",
    "* HDFS는 데이터 삭제 시 영구적 데이터를 삭제하지 않도록 휴지통 설정을 할 수 있음.\n",
    "    * fs.trash.interval\n",
    "    * fs.trash.checkpoint.interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HDFS 운영자 커맨드**\n",
    "* HDFS 의 각 노드들의 상태를 출력하며, HDFS의전체 사용량과 각 노드의 상태를 확인할 수 있음.\n",
    "    * dfsadmin -report\n",
    "\n",
    "**HDFS Balancers** (어려운 작업)\n",
    "* 하둡을 운영하다보면, 서로 다른 스펙의 데이터노드를 하나의 클러스터로 구성하게 됨.\n",
    "* 이 경우 노드 간 디스크 크기가 다를 수 있꼬, 전체 데이터의 밸런싱이되지 않는 문제가 될 수 있음.\n",
    "* 신규 데이터 노드를 추가하는 경우에도 발생할 수 있음.\n",
    "    * 이 경우 NameNode에서 데이터 적재량이 적은 노드를 우선적으로 선정하여 block을 추가하는데, 이 때 특정 노드에 부하가 몰릴 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Hadoop 2.0 Cluster Architecture**\n",
    "* Standby NameNode가 추가로있다는 것이 특징\n",
    "* Shared edit logs가 제일 중요.\n",
    "\n",
    "**네임노드 고가용성**\n",
    "* HDFS 고가용성은 이중화된 두 대의 서버인 액티브 네임노드와 스탠바이 네임노드를 이용하여 지원\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suhyun2",
   "language": "python",
   "name": "suhyun2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
